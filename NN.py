import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image, ImageOps
import openml
import os
import torch.nn as nn
import mlflow
import plotly.express as px
import shutil
import time
import random
from streamlit_drawable_canvas import st_canvas
from torch.utils.data import DataLoader, TensorDataset
import torch.optim as optim
import torch
from torchvision import transforms
from datetime import datetime
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from mlflow.tracking import MlflowClient
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split 



def mlflow_input():
    #st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")
    DAGSHUB_USERNAME = "Snxtruc"  # Thay b·∫±ng username c·ªßa b·∫°n
    DAGSHUB_REPO_NAME = "HocMayPython"
    DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

    # ƒê·∫∑t URI MLflow ƒë·ªÉ tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám MLflow
    mlflow.set_experiment("Neural Network")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"



def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp milliseconds th√†nh th·ªùi gian d·ªÖ ƒë·ªçc."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def display_mlflow_experiments():
    """Hi·ªÉn th·ªã danh s√°ch Runs trong MLflow."""
    st.title("üìä MLflow Experiment Viewer")

    mlflow_input()

    experiment_name = "Neural Network"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch Runs
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    # X·ª≠ l√Ω d·ªØ li·ªáu runs ƒë·ªÉ hi·ªÉn th·ªã
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_data = mlflow.get_run(run_id)
        run_tags = run_data.data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # L·∫•y t√™n t·ª´ tags n·∫øu c√≥
        created_time = format_time_relative(run_data.info.start_time)
        duration = (run_data.info.end_time - run_data.info.start_time) / 1000 if run_data.info.end_time else "ƒêang ch·∫°y"
        source = run_tags.get("mlflow.source.name", "Unknown")

        run_info.append({
            "Run Name": run_name,
            "Run ID": run_id,
            "Created": created_time,
            "Duration (s)": duration if isinstance(duration, str) else f"{duration:.1f}s",
            "Source": source
        })

    # S·∫Øp x·∫øp run theo th·ªùi gian ch·∫°y (m·ªõi nh·∫•t tr∆∞·ªõc)
    run_info_df = pd.DataFrame(run_info)
    run_info_df = run_info_df.sort_values(by="Created", ascending=False)

    # Hi·ªÉn th·ªã danh s√°ch Runs trong b·∫£ng
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs:")
    st.dataframe(run_info_df, use_container_width=True)

    # Ch·ªçn Run t·ª´ dropdown
    run_names = run_info_df["Run Name"].tolist()
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", run_names)

    # L·∫•y Run ID t∆∞∆°ng ·ª©ng
    selected_run_id = run_info_df.loc[run_info_df["Run Name"] == selected_run_name, "Run ID"].values[0]

    # L·∫•y th√¥ng tin Run
    selected_run = mlflow.get_run(selected_run_id)

    # --- üìù ƒê·ªîI T√äN RUN ---
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", selected_run_name)
    if st.button("üíæ L∆∞u t√™n m·ªõi"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_run_name)
            st.success(f"‚úÖ ƒê√£ ƒë·ªïi t√™n th√†nh **{new_run_name}**. H√£y t·∫£i l·∫°i trang ƒë·ªÉ th·∫•y thay ƒë·ªïi!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {e}")

    # --- üóëÔ∏è X√ìA RUN ---
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"‚úÖ ƒê√£ x√≥a run **{selected_run_name}**! H√£y t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x√≥a run: {e}")

    # --- HI·ªÇN TH·ªä CHI TI·∫æT RUN ---
    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")

        start_time_ms = selected_run.info.start_time
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Hi·ªÉn th·ªã model artifact (n·∫øu c√≥)
        model_artifact_path = f"{st.session_state['mlflow_url']}/{selected_experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### üìÇ Model Artifact:")
        st.write(f"üì• [T·∫£i m√¥ h√¨nh]({model_artifact_path})")

    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")

def up_load_db():
    st.header("üì• T·∫£i D·ªØ Li·ªáu")
    
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("üî∏ **D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n r·ªìi!** B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c v·ªõi c√°c b∆∞·ªõc ti·∫øp theo.")
    else:
        option = st.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", ["T·∫£i t·ª´ OpenML", "Upload d·ªØ li·ªáu"], key="data_source_radio")
        
        if "data" not in st.session_state:
            st.session_state.data = None
        
        if option == "T·∫£i t·ª´ OpenML":
            st.markdown("#### üìÇ T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML")
            if st.button("T·∫£i d·ªØ li·ªáu MNIST", key="download_mnist_button"):
                with st.status("üîÑ ƒêang t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent_complete in range(0, 101, 20):
                        time.sleep(0.5)
                        progress_bar.progress(percent_complete)
                        status.update(label=f"üîÑ ƒêang t·∫£i... ({percent_complete}%)")
                    
                    X = np.load("X.npy")
                    y = np.load("y.npy")
                    
                    status.update(label="‚úÖ T·∫£i d·ªØ li·ªáu th√†nh c√¥ng!", state="complete")
                    
                    st.session_state.data = (X, y)
        
        else:
            st.markdown("#### üì§ Upload d·ªØ li·ªáu c·ªßa b·∫°n")
            uploaded_file = st.file_uploader("Ch·ªçn m·ªôt file ·∫£nh", type=["png", "jpg", "jpeg"], key="file_upload")
            
            if uploaded_file is not None:
                with st.status("üîÑ ƒêang x·ª≠ l√Ω ·∫£nh...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent_complete in range(0, 101, 25):
                        time.sleep(0.3)
                        progress_bar.progress(percent_complete)
                        status.update(label=f"üîÑ ƒêang x·ª≠ l√Ω... ({percent_complete}%)")
                    
                    image = Image.open(uploaded_file).convert('L')
                    st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)
                    
                    if image.size != (28, 28):
                        status.update(label="‚ùå ·∫¢nh kh√¥ng ƒë√∫ng k√≠ch th∆∞·ªõc 28x28 pixel.", state="error")
                    else:
                        status.update(label="‚úÖ ·∫¢nh h·ª£p l·ªá!", state="complete")
                        transform = transforms.Compose([
                            transforms.ToTensor(),
                            transforms.Normalize((0.5,), (0.5,))
                        ])
                        image_tensor = transform(image).unsqueeze(0)
                        st.session_state.data = image_tensor
    
    if st.session_state.data is not None:
        st.markdown("#### ‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!")
    else:
        st.warning("üî∏ Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øp t·ª•c l√†m vi·ªác.")
    
    st.markdown("""
    üîπ **L∆∞u √Ω:**
    - ·ª®ng d·ª•ng ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu ·∫£nh d·∫°ng **28x28 pixel (grayscale)**.
    - D·ªØ li·ªáu ph·∫£i c√≥ c·ªôt **'label'** ch·ª©a nh√£n (s·ªë t·ª´ 0 ƒë·∫øn 9) khi t·∫£i t·ª´ OpenML.
    - N·∫øu d·ªØ li·ªáu c·ªßa b·∫°n kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng, vui l√≤ng s·ª≠ d·ª•ng d·ªØ li·ªáu MNIST t·ª´ OpenML.
    """)

def chia_du_lieu():
    st.markdown(" ### üìå Chia d·ªØ li·ªáu Train/Test")

    # Ki·ªÉm tra n·∫øu d·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c t·∫£i l√™n
    if "data" not in st.session_state or st.session_state.data is None:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! B·∫°n c·∫ßn t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi th·ª±c hi·ªán chia t·∫≠p Train/Test.")
        return  # D·ª´ng l·∫°i n·∫øu ch∆∞a c√≥ d·ªØ li·ªáu

    # ƒê·ªçc d·ªØ li·ªáu t·ª´ session_state
    X, y = st.session_state.data
    total_samples = X.shape[0]

    # N·∫øu ch∆∞a c√≥ c·ªù "data_split_done", ƒë·∫∑t m·∫∑c ƒë·ªãnh l√† False
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider("üìå Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:", 1000, total_samples, min(10000, total_samples))
    
    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong ph·∫ßn Train)", 0, 50, 15)
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u") and not st.session_state.data_split_done:
        st.session_state.data_split_done = True  # ƒê√°nh d·∫•u ƒë√£ chia d·ªØ li·ªáu
        
        # Thanh ti·∫øn tr√¨nh
        progress_bar = st.progress(0)
        status_text = st.empty()

        status_text.text("üîÑ ƒêang ch·ªçn d·ªØ li·ªáu (0%)")

        # Ch·ªçn d·ªØ li·ªáu
        if num_samples == total_samples:
            X_selected, y_selected = X, y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples, stratify=y if len(np.unique(y)) > 1 else None, random_state=42
            )
        
        progress_bar.progress(25)
        status_text.text("üîÑ ƒêang chia t·∫≠p Train/Test (50%)")
        
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_size/100, stratify=y_selected if len(np.unique(y_selected)) > 1 else None, random_state=42
        )
        progress_bar.progress(50)

        status_text.text("üîÑ ƒêang chia t·∫≠p Train/Validation (75%)")
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full, test_size=val_size / (100 - test_size),
            stratify=y_train_full if len(np.unique(y_train_full)) > 1 else None, random_state=42
        )
        progress_bar.progress(75)

        # L∆∞u d·ªØ li·ªáu v√†o session_state
        st.session_state.update({
            "total_samples": num_samples,
            "X_train": X_train,
            "X_val": X_val,
            "X_test": X_test,
            "y_train": y_train,
            "y_val": y_val,
            "y_test": y_test,
            "test_size": X_test.shape[0],
            "val_size": X_val.shape[0],
            "train_size": X_train.shape[0]
        })

        progress_bar.progress(100)
        status_text.text("‚úÖ Ho√†n th√†nh chia d·ªØ li·ªáu (100%)")

        # Hi·ªÉn th·ªã th√¥ng tin chia d·ªØ li·ªáu
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia, kh√¥ng c·∫ßn ch·∫°y l·∫°i.")

class NeuralNet(nn.Module):
    def __init__(self, input_size, num_layers, num_nodes, activation):
        super(NeuralNet, self).__init__()
        layers = [nn.Linear(input_size, num_nodes), activation()]
        for _ in range(num_layers - 1):
            layers.append(nn.Linear(num_nodes, num_nodes))
            layers.append(activation())
        layers.append(nn.Linear(num_nodes, 10))  # Output layer (10 classes)
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)

def train():
    if "mlflow_url" not in st.session_state:
        st.session_state["mlflow_url"] = "https://dagshub.com/Snxtruc/HocMayPython.mlflow"

    mlflow_input()

    if not all(k in st.session_state for k in ["X_train", "X_val", "X_test"]):
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh tensor
    X_train = torch.tensor(st.session_state["X_train"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    X_val = torch.tensor(st.session_state["X_val"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32) if st.session_state["X_val"].size > 0 else None
    X_test = torch.tensor(st.session_state["X_test"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    y_train = torch.tensor(st.session_state["y_train"], dtype=torch.long)
    y_val = torch.tensor(st.session_state["y_val"], dtype=torch.long) if X_val is not None else None
    y_test = torch.tensor(st.session_state["y_test"], dtype=torch.long)

    # Chia batch ƒë·ªÉ hu·∫•n luy·ªán th·ª±c t·∫ø h∆°n
    batch_size = 64
    train_dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # Giao di·ªán t√πy ch·ªânh m√¥ h√¨nh
    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")
    num_layers = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
    num_nodes = st.slider("S·ªë node m·ªói l·ªõp", 32, 256, 128)
    activation_func = st.selectbox("H√†m k√≠ch ho·∫°t", ["ReLU", "Sigmoid", "Tanh"])
    optimizer_choice = st.selectbox("Optimizer", ["Adam", "SGD", "RMSprop"])
    learning_rate = st.slider("Learning Rate", 1e-5, 1e-1, 1e-3, format="%.5f")
    epochs = st.slider("S·ªë epoch", 1, 50, 10)
    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "Default_Run")
    st.session_state["run_name"] = run_name if run_name else "default_run"

    activation_dict = {"ReLU": nn.ReLU, "Sigmoid": nn.Sigmoid, "Tanh": nn.Tanh}
    activation = activation_dict[activation_func]
    
    model = NeuralNet(28 * 28, num_layers, num_nodes, activation)
    criterion = nn.CrossEntropyLoss()

    optimizer_dict = {
        "Adam": optim.Adam(model.parameters(), lr=learning_rate),
        "SGD": optim.SGD(model.parameters(), lr=learning_rate),
        "RMSprop": optim.RMSprop(model.parameters(), lr=learning_rate),
    }
    optimizer = optimizer_dict[optimizer_choice]

    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            mlflow.log_params({
                "num_layers": num_layers,
                "num_nodes": num_nodes,
                "activation": activation_func,
                "optimizer": optimizer_choice,
                "learning_rate": learning_rate,
                "epochs": epochs,
            })

            progress_bar = st.progress(0)
            status_text = st.empty()

            train_losses = []
            val_accuracies = []

            for epoch in range(epochs):
                model.train()
                epoch_loss = 0
                for batch_X, batch_y in train_loader:
                    optimizer.zero_grad()
                    outputs = model(batch_X)
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    optimizer.step()
                    epoch_loss += loss.item()

                train_losses.append(epoch_loss / len(train_loader))

                model.eval()
                with torch.no_grad():
                    val_acc = None
                    if X_val is not None:
                        val_preds = model(X_val).argmax(dim=1)
                        val_acc = (val_preds == y_val).float().mean().item()
                        val_accuracies.append(val_acc)

                progress = int((epoch + 1) / epochs * 100)
                progress_bar.progress(progress / 100)

                if val_acc is not None:
                    status_text.text(f"üõ†Ô∏è Epoch {epoch + 1}/{epochs} | Loss: {train_losses[-1]:.4f} | Val Acc: {val_acc:.4f} | {progress}%")
                else:
                    status_text.text(f"üõ†Ô∏è Epoch {epoch + 1}/{epochs} | Loss: {train_losses[-1]:.4f} | {progress}%")
                
                time.sleep(0.5)

            model.eval()
            with torch.no_grad():
                train_acc = (model(X_train).argmax(dim=1) == y_train).float().mean().item()
                test_acc = (model(X_test).argmax(dim=1) == y_test).float().mean().item()
                val_acc = np.mean(val_accuracies) if val_accuracies else None

            if val_acc is not None:
                st.success(f"üìä **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation**: {val_acc:.4f}")
                st.success(f"üìä **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p train**: {train_acc:.4f}")

            mlflow.log_metrics({
                "train_accuracy": train_acc,
                "test_accuracy": test_acc,
                "final_train_loss": train_losses[-1],
            })
            if val_acc is not None:
                mlflow.log_metric("val_accuracy", val_acc)

            # üî• G·ªçi h√†m l∆∞u model
            save_model(model, num_layers, num_nodes, activation_func)

            progress_bar.progress(1.0)
            status_text.text("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
            st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")

# ‚úÖ H√ÄM M·ªöI: Save Model
def save_model(model, num_layers, num_nodes, activation_func):
    model_name = f"{st.session_state['run_name']}_{num_layers}layers_{num_nodes}nodes_{activation_func}"
    
    # Tr√°nh tr√πng t√™n model
    if "neural_models" not in st.session_state:
        st.session_state["neural_models"] = []

    existing_names = {m["name"] for m in st.session_state["neural_models"]}
    while model_name in existing_names:
        model_name += "_new"

    model_path = f"{model_name}.pth"
    torch.save({
        "num_layers": num_layers,
        "num_nodes": num_nodes,
        "activation_func": activation_func,
        "model_state_dict": model.state_dict()
    }, model_path)
    
    st.session_state["neural_models"].append({"name": model_name, "model": model_path})
    st.session_state["trained_model"] = model  # ‚úÖ Load ngay v√†o session_state
    st.success(f"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh: `{model_name}`")



# H√†m x·ª≠ l√Ω ·∫£nh
def preprocess_canvas_image(canvas_result):
    # Ki·ªÉm tra n·∫øu canvas tr·ªëng
    if canvas_result is None or canvas_result.image_data is None:
        return None

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu t·ª´ canvas th√†nh numpy array
    image_array = np.array(canvas_result.image_data, dtype=np.uint8)

    # ƒê·∫£m b·∫£o ·∫£nh c√≥ ƒë√∫ng 3 k√™nh (RGB), n·∫øu kh√¥ng, chuy·ªÉn ƒë·ªïi
    if image_array.shape[-1] == 4:  # N·∫øu c√≥ k√™nh Alpha (RGBA), lo·∫°i b·ªè
        image_array = image_array[:, :, :3]

    # Chuy·ªÉn numpy array th√†nh ·∫£nh PIL
    image_pil = Image.fromarray(image_array)

    # Chuy·ªÉn sang ·∫£nh x√°m (grayscale) v√† resize v·ªÅ 28x28
    image_pil = ImageOps.grayscale(image_pil)  
    image_pil = image_pil.resize((28, 28))  

    # Chuy·ªÉn ƒë·ªïi ·∫£nh th√†nh tensor ƒë·ªÉ ƒë∆∞a v√†o model
    transform = transforms.Compose([
        transforms.ToTensor(),  
        transforms.Normalize((0.5,), (0.5,))  
    ])
    
    image_tensor = transform(image_pil).view(-1, 28 * 28)  
    return image_tensor


def demo():
    # Giao di·ªán Streamlit
    st.title("üì∑ Nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay")
    
    # üì• Load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("‚úÖ ƒê√£ s·ª≠ d·ª•ng m√¥ h√¨nh v·ª´a hu·∫•n luy·ªán!")
    else:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh! H√£y hu·∫•n luy·ªán tr∆∞·ªõc.")
        return  # D·ª´ng ch∆∞∆°ng tr√¨nh n·∫øu ch∆∞a c√≥ m√¥ h√¨nh

    # üÜï C·∫≠p nh·∫≠t key cho canvas khi nh·∫•n "T·∫£i l·∫°i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("üîÑ T·∫£i l·∫°i n·∫øu kh√¥ng th·∫•y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # ‚úçÔ∏è V·∫Ω s·ªë
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("D·ª± ƒëo√°n s·ªë"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            # Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω
            st.image(Image.fromarray((img.numpy().reshape(28, 28) * 255).astype(np.uint8)), caption="·∫¢nh sau x·ª≠ l√Ω", width=100)

            # üß† D·ª± ƒëo√°n s·ªë
            model.eval()  # Chuy·ªÉn sang ch·∫ø ƒë·ªô ƒë√°nh gi√°
            with torch.no_grad():
                logits = model(img)  # ƒê·∫ßu ra tr∆∞·ªõc khi √°p d·ª•ng softmax
                prediction = logits.argmax(dim=1).item()  # L·∫•y class c√≥ x√°c su·∫•t cao nh·∫•t
                confidence_scores = torch.nn.functional.softmax(logits, dim=1)  # Chuy·ªÉn th√†nh x√°c su·∫•t
                max_confidence = confidence_scores.max().item()  # L·∫•y x√°c su·∫•t cao nh·∫•t

            # üèÜ Hi·ªÉn th·ªã k·∫øt qu·∫£
            st.subheader(f"üî¢ D·ª± ƒëo√°n: {prediction}")
            st.write(f"üìä M·ª©c ƒë·ªô tin c·∫≠y: {max_confidence:.2%}")

            # üìä Hi·ªÉn th·ªã b·∫£ng confidence score
            prob_df = pd.DataFrame(confidence_scores.numpy(), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["M·ª©c ƒë·ªô tin c·∫≠y"]
        else:
            st.error("‚ö†Ô∏è H√£y v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi b·∫•m D·ª± ƒëo√°n!")

def NeuranNetwork():
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    ) 
    st.markdown(" ### üñäÔ∏è MNIST Neural Network App")
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
    ["T·ªïng quan", 
    "T·∫£i d·ªØ li·ªáu",
    "Chia d·ªØ li·ªáu",
    "Hu·∫•n luy·ªán", 
    "Th√¥ng tin hu·∫•n luy·ªán",
    "Demo"
    ])

    with tab2: 
        up_load_db()
    with tab3: 
        chia_du_lieu()
    with tab4:
        train()
    with tab5:
        display_mlflow_experiments()
    with tab6:
        demo()

def run():
    NeuranNetwork()
if __name__ == "__main__":
    run()
