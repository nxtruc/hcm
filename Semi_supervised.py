import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import openml
import os
import mlflow
import plotly.express as px
import shutil
import time
import torch
from torchvision import transforms
from torch.utils.data import TensorDataset, DataLoader
from datetime import datetime
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score
from mlflow.tracking import MlflowClient
from sklearn.model_selection import train_test_split 

def mlflow_input():
    #st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")
    DAGSHUB_USERNAME = "Snxtruc"  # Thay b·∫±ng username c·ªßa b·∫°n
    DAGSHUB_REPO_NAME = "HocMayPython"
    DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

    # ƒê·∫∑t URI MLflow ƒë·ªÉ tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám MLflow
    mlflow.set_experiment("Semi-supervised")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"

def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp milliseconds th√†nh th·ªùi gian d·ªÖ ƒë·ªçc."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def display_mlflow_experiments():
    """Hi·ªÉn th·ªã danh s√°ch Runs trong MLflow."""
    st.title("üìä MLflow Experiment Viewer")

    mlflow_input()

    experiment_name = "Neural Network"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch Runs
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    # X·ª≠ l√Ω d·ªØ li·ªáu runs ƒë·ªÉ hi·ªÉn th·ªã
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_data = mlflow.get_run(run_id)
        run_tags = run_data.data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # L·∫•y t√™n t·ª´ tags n·∫øu c√≥
        created_time = format_time_relative(run_data.info.start_time)
        duration = (run_data.info.end_time - run_data.info.start_time) / 1000 if run_data.info.end_time else "ƒêang ch·∫°y"
        source = run_tags.get("mlflow.source.name", "Unknown")

        run_info.append({
            "Run Name": run_name,
            "Run ID": run_id,
            "Created": created_time,
            "Duration (s)": duration if isinstance(duration, str) else f"{duration:.1f}s",
            "Source": source
        })

    # S·∫Øp x·∫øp run theo th·ªùi gian ch·∫°y (m·ªõi nh·∫•t tr∆∞·ªõc)
    run_info_df = pd.DataFrame(run_info)
    run_info_df = run_info_df.sort_values(by="Created", ascending=False)

    # Hi·ªÉn th·ªã danh s√°ch Runs trong b·∫£ng
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs:")
    st.dataframe(run_info_df, use_container_width=True)

    # Ch·ªçn Run t·ª´ dropdown
    run_names = run_info_df["Run Name"].tolist()
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", run_names)

    # L·∫•y Run ID t∆∞∆°ng ·ª©ng
    selected_run_id = run_info_df.loc[run_info_df["Run Name"] == selected_run_name, "Run ID"].values[0]

    # L·∫•y th√¥ng tin Run
    selected_run = mlflow.get_run(selected_run_id)

    # --- üìù ƒê·ªîI T√äN RUN ---
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", selected_run_name)
    if st.button("üíæ L∆∞u t√™n m·ªõi"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_run_name)
            st.success(f"‚úÖ ƒê√£ ƒë·ªïi t√™n th√†nh **{new_run_name}**. H√£y t·∫£i l·∫°i trang ƒë·ªÉ th·∫•y thay ƒë·ªïi!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {e}")

    # --- üóëÔ∏è X√ìA RUN ---
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"‚úÖ ƒê√£ x√≥a run **{selected_run_name}**! H√£y t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x√≥a run: {e}")

    # --- HI·ªÇN TH·ªä CHI TI·∫æT RUN ---
    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")

        start_time_ms = selected_run.info.start_time
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Hi·ªÉn th·ªã model artifact (n·∫øu c√≥)
        model_artifact_path = f"{st.session_state['mlflow_url']}/{selected_experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### üìÇ Model Artifact:")
        st.write(f"üì• [T·∫£i m√¥ h√¨nh]({model_artifact_path})")

    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")

def tong_quan():
    st.title("T·ªïng quan v·ªÅ t·∫≠p d·ªØ li·ªáu MNIST")

    st.header("1. Gi·ªõi thi·ªáu")
    st.write("T·∫≠p d·ªØ li·ªáu MNIST (Modified National Institute of Standards and Technology) l√† m·ªôt trong nh·ªØng t·∫≠p d·ªØ li·ªáu ph·ªï bi·∫øn nh·∫•t trong lƒ©nh v·ª±c Machine Learning v√† Computer Vision, th∆∞·ªùng ƒë∆∞·ª£c d√πng ƒë·ªÉ hu·∫•n luy·ªán v√† ki·ªÉm th·ª≠ c√°c m√¥ h√¨nh ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay.") 

    st.image("https://datasets.activeloop.ai/wp-content/uploads/2019/12/MNIST-handwritten-digits-dataset-visualized-by-Activeloop.webp", use_container_width=True)

    st.subheader("N·ªôi dung")
    st.write("- 70.000 ·∫£nh grayscale (ƒëen tr·∫Øng) c·ªßa c√°c ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9.")
    st.write("- K√≠ch th∆∞·ªõc ·∫£nh: 28x28 pixel.")
    st.write("- ƒê·ªãnh d·∫°ng: M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng m·ªôt ma tr·∫≠n 28x28 c√≥ gi√° tr·ªã pixel t·ª´ 0 (ƒëen) ƒë·∫øn 255 (tr·∫Øng).")
    st.write("- Nh√£n: M·ªôt s·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9 t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë trong ·∫£nh.")

    st.header("2. Ngu·ªìn g·ªëc v√† √Ω nghƒ©a")
    st.write("- ƒê∆∞·ª£c t·∫°o ra t·ª´ b·ªô d·ªØ li·ªáu ch·ªØ s·ªë vi·∫øt tay g·ªëc c·ªßa NIST, do LeCun, Cortes v√† Burges chu·∫©n b·ªã.")
    st.write("- D√πng l√†m benchmark cho c√°c thu·∫≠t to√°n nh·∫≠n di·ªán h√¨nh ·∫£nh, ƒë·∫∑c bi·ªát l√† m·∫°ng n∆°-ron nh√¢n t·∫°o (ANN) v√† m·∫°ng n∆°-ron t√≠ch ch·∫≠p (CNN).")
    st.write("- R·∫•t h·ªØu √≠ch cho vi·ªác ki·ªÉm th·ª≠ m√¥ h√¨nh tr√™n d·ªØ li·ªáu h√¨nh ·∫£nh th·ª±c t·∫ø nh∆∞ng ƒë∆°n gi·∫£n.")

    st.header("3. Ph√¢n chia t·∫≠p d·ªØ li·ªáu")
    st.write("- T·∫≠p hu·∫•n luy·ªán: 60.000 ·∫£nh.")
    st.write("- T·∫≠p ki·ªÉm th·ª≠: 10.000 ·∫£nh.")
    st.write("- M·ªói t·∫≠p c√≥ ph√¢n b·ªë ƒë·ªìng ƒë·ªÅu v·ªÅ s·ªë l∆∞·ª£ng ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.")

    st.header("4. ·ª®ng d·ª•ng")
    st.write("- Hu·∫•n luy·ªán v√† ƒë√°nh gi√° c√°c thu·∫≠t to√°n nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay.")
    st.write("- Ki·ªÉm th·ª≠ v√† so s√°nh hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh h·ªçc s√¢u (Deep Learning).")
    st.write("- L√†m b√†i t·∫≠p th·ª±c h√†nh v·ªÅ x·ª≠ l√Ω ·∫£nh, tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng, m√¥ h√¨nh ph√¢n lo·∫°i.")
    st.write("- Cung c·∫•p m·ªôt baseline ƒë∆°n gi·∫£n cho c√°c b√†i to√°n li√™n quan ƒë·∫øn Computer Vision.")

    st.header("5. Ph∆∞∆°ng ph√°p ti·∫øp c·∫≠n ph·ªï bi·∫øn")
    st.write("- Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng truy·ªÅn th·ªëng: PCA, HOG, SIFT...")
    st.write("- Machine Learning: KNN, SVM, Random Forest, Logistic Regression...")
    st.write("- Deep Learning: MLP, CNN (LeNet-5, AlexNet, ResNet...), RNN")

    st.caption("·ª®ng d·ª•ng hi·ªÉn th·ªã th√¥ng tin v·ªÅ t·∫≠p d·ªØ li·ªáu MNIST b·∫±ng Streamlit üöÄ")

def up_load_db():
    st.header("üì• T·∫£i D·ªØ Li·ªáu")
    
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("üî∏ **D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n r·ªìi!** B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c v·ªõi c√°c b∆∞·ªõc ti·∫øp theo.")
    else:
        option = st.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", ["T·∫£i t·ª´ OpenML", "Upload d·ªØ li·ªáu"], key="data_source_radio")
        
        if "data" not in st.session_state:
            st.session_state.data = None
        
        if option == "T·∫£i t·ª´ OpenML":
            st.markdown("#### üìÇ T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML")
            if st.button("T·∫£i d·ªØ li·ªáu MNIST", key="download_mnist_button"):
                with st.status("üîÑ ƒêang t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent_complete in range(0, 101, 20):
                        time.sleep(0.5)
                        progress_bar.progress(percent_complete)
                        status.update(label=f"üîÑ ƒêang t·∫£i... ({percent_complete}%)")
                    
                    X = np.load("X.npy")
                    y = np.load("y.npy")
                    
                    status.update(label="‚úÖ T·∫£i d·ªØ li·ªáu th√†nh c√¥ng!", state="complete")
                    
                    st.session_state.data = (X, y)
        
        else:
            st.markdown("#### üì§ Upload d·ªØ li·ªáu c·ªßa b·∫°n")
            uploaded_file = st.file_uploader("Ch·ªçn m·ªôt file ·∫£nh", type=["png", "jpg", "jpeg"], key="file_upload")
            
            if uploaded_file is not None:
                with st.status("üîÑ ƒêang x·ª≠ l√Ω ·∫£nh...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent_complete in range(0, 101, 25):
                        time.sleep(0.3)
                        progress_bar.progress(percent_complete)
                        status.update(label=f"üîÑ ƒêang x·ª≠ l√Ω... ({percent_complete}%)")
                    
                    image = Image.open(uploaded_file).convert('L')
                    st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)
                    
                    if image.size != (28, 28):
                        status.update(label="‚ùå ·∫¢nh kh√¥ng ƒë√∫ng k√≠ch th∆∞·ªõc 28x28 pixel.", state="error")
                    else:
                        status.update(label="‚úÖ ·∫¢nh h·ª£p l·ªá!", state="complete")
                        transform = transforms.Compose([
                            transforms.ToTensor(),
                            transforms.Normalize((0.5,), (0.5,))
                        ])
                        image_tensor = transform(image).unsqueeze(0)
                        st.session_state.data = image_tensor
    
    if st.session_state.data is not None:
        st.markdown("#### ‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!")
    else:
        st.warning("üî∏ Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øp t·ª•c l√†m vi·ªác.")
    
    st.markdown("""
    üîπ **L∆∞u √Ω:**
    - ·ª®ng d·ª•ng ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu ·∫£nh d·∫°ng **28x28 pixel (grayscale)**.
    - D·ªØ li·ªáu ph·∫£i c√≥ c·ªôt **'label'** ch·ª©a nh√£n (s·ªë t·ª´ 0 ƒë·∫øn 9) khi t·∫£i t·ª´ OpenML.
    - N·∫øu d·ªØ li·ªáu c·ªßa b·∫°n kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng, vui l√≤ng s·ª≠ d·ª•ng d·ªØ li·ªáu MNIST t·ª´ OpenML.
    """)

def chia_du_lieu():
    st.title("üìå Chia d·ªØ li·ªáu Train/Test")

    # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ c√≥ ch∆∞a
    if "data" not in st.session_state or st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi th·ª±c hi·ªán chia d·ªØ li·ªáu.")
        return

    # L·∫•y d·ªØ li·ªáu t·ª´ session_state
    X, y = st.session_state.data
    total_samples = X.shape[0]

    # N·∫øu ch∆∞a c√≥ flag "data_split_done", m·∫∑c ƒë·ªãnh l√† False
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.number_input("üìå Nh·∫≠p s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:", min_value=1000, max_value=total_samples, value=20000, step=1000)
    
    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    train_size = 100 - test_size
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Train={train_size}%, Test={test_size}%")

    # Placeholder cho b·∫£ng k·∫øt qu·∫£ v√† thanh ti·∫øn tr√¨nh
    progress_bar = st.empty()
    table_placeholder = st.empty()

    # N√∫t x√°c nh·∫≠n chia d·ªØ li·ªáu
    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u", key="luu"):
        progress_bar.progress(10)  # B·∫Øt ƒë·∫ßu ti·∫øn tr√¨nh
        st.session_state.data_split_done = True  # ƒê√°nh d·∫•u ƒë√£ chia d·ªØ li·ªáu
        
        # Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu c·∫ßn l·∫•y
        if num_samples == total_samples:
            X_selected, y_selected = X, y
        else:
            X_selected, _, y_selected, _ = train_test_split(
                X, y, train_size=num_samples, stratify=y, random_state=42
            )

        progress_bar.progress(40)  # Ti·∫øn tr√¨nh 40%

        # Chia train/test
        stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train, X_test, y_train, y_test = train_test_split(
            X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
        )

        progress_bar.progress(70)  # Ti·∫øn tr√¨nh 70%

        # L∆∞u v√†o session_state
        st.session_state.total_samples = num_samples
        st.session_state["neural_X_train"] = X_train
        st.session_state["neural_X_test"] = X_test
        st.session_state["neural_y_train"] = y_train
        st.session_state["neural_y_test"] = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.train_size = X_train.shape[0]

        progress_bar.progress(90)  # G·∫ßn ho√†n t·∫•t

        # L∆∞u b·∫£ng k·∫øt qu·∫£
        st.session_state.summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]]
        })

        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        table_placeholder.table(st.session_state.summary_df)
        progress_bar.progress(100)  # Ho√†n th√†nh

    # N·∫øu ƒë√£ chia d·ªØ li·ªáu tr∆∞·ªõc ƒë√≥
    if st.session_state.data_split_done:
        if "summary_df" in st.session_state:
            table_placeholder.table(st.session_state.summary_df)
        
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia. Nh·∫•n n√∫t d∆∞·ªõi ƒë√¢y ƒë·ªÉ chia l·∫°i n·∫øu mu·ªën thay ƒë·ªïi.")
        
        if st.button("üîÑ Chia l·∫°i d·ªØ li·ªáu", key="chia_lai"):
            progress_bar.progress(10)  # B·∫Øt ƒë·∫ßu l·∫°i ti·∫øn tr√¨nh
            table_placeholder.empty()

            if num_samples == total_samples:
                X_selected, y_selected = X, y
            else:
                X_selected, _, y_selected, _ = train_test_split(
                    X, y, train_size=num_samples, stratify=y, random_state=42
                )

            progress_bar.progress(40)

            # Chia train/test
            stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
            )

            progress_bar.progress(70)

            # L∆∞u v√†o session_state
            st.session_state.total_samples = num_samples
            st.session_state["neural_X_train"] = X_train
            st.session_state["neural_X_test"] = X_test
            st.session_state["neural_y_train"] = y_train
            st.session_state["neural_y_test"] = y_test
            st.session_state.test_size = X_test.shape[0]
            st.session_state.train_size = X_train.shape[0]

            progress_bar.progress(90)

            # C·∫≠p nh·∫≠t b·∫£ng k·∫øt qu·∫£ m·ªõi
            st.session_state.summary_df = pd.DataFrame({
                "T·∫≠p d·ªØ li·ªáu": ["Train", "Test"],
                "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_test.shape[0]]
            })
            st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia l·∫°i th√†nh c√¥ng!")
            table_placeholder.table(st.session_state.summary_df)
            progress_bar.progress(100)  # Ho√†n th√†nh


#Callback phuc vu train2
class ProgressBarCallback:
    def __init__(self, total_epochs, progress_bar, status_text, max_train_progress=80):
        self.total_epochs = total_epochs
        self.progress_bar = progress_bar
        self.status_text = status_text
        self.max_train_progress = max_train_progress

    def on_epoch_begin(self, epoch):
        progress = (epoch + 1) / self.total_epochs * self.max_train_progress
        self.progress_bar.progress(min(int(progress), self.max_train_progress))
        self.status_text.text(f"üõ†Ô∏è ƒêang hu·∫•n luy·ªán m√¥ h√¨nh... Epoch {epoch + 1}/{self.total_epochs}")

    def on_train_end(self):
        self.progress_bar.progress(self.max_train_progress)
        self.status_text.text("‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh ho√†n t·∫•t, ƒëang chu·∫©n b·ªã logging...")

class NeuralNet(nn.Module):
    def __init__(self, input_size, num_layers, num_nodes, activation):
        super(NeuralNet, self).__init__()
        layers = [nn.Linear(input_size, num_nodes), self.get_activation(activation)]
        
        for _ in range(num_layers - 1):
            layers.append(nn.Linear(num_nodes, num_nodes))
            layers.append(self.get_activation(activation))
        
        layers.append(nn.Linear(num_nodes, 10))  # Output layer
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

    def get_activation(self, activation):
        """ Tr·∫£ v·ªÅ h√†m k√≠ch ho·∫°t ph√π h·ª£p """
        if activation == "relu":
            return nn.ReLU()
        elif activation == "sigmoid":
            return nn.Sigmoid()
        elif activation == "tanh":
            return nn.Tanh()
        else:
            raise ValueError(f"Kh√¥ng h·ªó tr·ª£ activation: {activation}")

def train2():
    st.header("‚öôÔ∏è Pseudo Labelling v·ªõi Neural Network (PyTorch)")
    
    if "neural_X_train" not in st.session_state or "neural_X_test" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    
    X_train_full = torch.tensor(st.session_state["neural_X_train"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    y_train_full = torch.tensor(st.session_state["neural_y_train"], dtype=torch.long)
    X_test = torch.tensor(st.session_state["neural_X_test"].reshape(-1, 28 * 28) / 255.0, dtype=torch.float32)
    y_test = torch.tensor(st.session_state["neural_y_test"], dtype=torch.long)
    
    # L·∫•y 1% d·ªØ li·ªáu ban ƒë·∫ßu
    X_initial, y_initial = [], []
    for digit in range(10):
        indices = torch.where(y_train_full == digit)[0]
        num_samples = max(1, int(0.01 * len(indices)))
        selected_indices = indices[torch.randperm(len(indices))[:num_samples]]
        X_initial.append(X_train_full[selected_indices])
        y_initial.append(y_train_full[selected_indices])
    
    X_initial = torch.cat(X_initial, dim=0)
    y_initial = torch.cat(y_initial, dim=0)
    mask = torch.ones(len(X_train_full), dtype=torch.bool)
    mask[selected_indices] = False
    X_unlabeled = X_train_full[mask]
    
    # Ch·ªçn ch·∫ø ƒë·ªô l·∫∑p
    loop_mode = st.selectbox("Ch·ªçn ch·∫ø ƒë·ªô l·∫∑p:", ["S·ªë v√≤ng l·∫∑p c·ªë ƒë·ªãnh", "G√°n h·∫øt to√†n b·ªô t·∫≠p train"], key="pseudo_iteration_mode")
    
    if loop_mode == "S·ªë v√≤ng l·∫∑p c·ªë ƒë·ªãnh":
        max_iterations = st.slider("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", 1, 10, 5, key="pseudo_max_iter")
    else:
        st.warning("‚ö†Ô∏è Th·ªùi gian s·∫Ω l√¢u do c√≥ th·ªÉ l·∫∑p nhi·ªÅu khi ch·ªçn 'G√°n h·∫øt to√†n b·ªô t·∫≠p train'!")
        max_iterations = float('inf')
    
    # Hyperparameters
    num_layers = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
    num_nodes = st.slider("S·ªë node m·ªói l·ªõp", 32, 256, 128)
    activation = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "sigmoid", "tanh"])
    epochs = st.slider("S·ªë epoch m·ªói v√≤ng", 1, 50, 10)
    threshold = st.slider("Ng∆∞·ª°ng g√°n nh√£n", 0.5, 1.0, 0.95, step=0.01)
    learn_rate = st.number_input("T·ªëc ƒë·ªô h·ªçc", min_value=0.0001, max_value=0.1, value=0.001, step=0.0001, format="%.4f")
    
    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "Pseudo_Default_Run")
    
    if st.button("B·∫Øt ƒë·∫ßu Pseudo Labelling"):
        mlflow.start_run(run_name=f"Pseudo_{run_name}")
        model = NeuralNet(28 * 28, num_layers, num_nodes, activation)
        optimizer = optim.Adam(model.parameters(), lr=learn_rate)
        criterion = nn.CrossEntropyLoss()
        
        X_labeled, y_labeled = X_initial.clone(), y_initial.clone()
        X_unlabeled_remaining = X_unlabeled.clone()
        total_samples = len(X_train_full)
        
        iteration = 0
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        while iteration < max_iterations:
            st.write(f"### V√≤ng l·∫∑p {iteration + 1}")
            train_dataset = TensorDataset(X_labeled, y_labeled)
            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
            
            model.train()
            for epoch in range(epochs):
                status_text.text(f"üöÄ ƒêang train - Epoch {epoch + 1}/{epochs}...")
                progress_bar.progress(int((epoch + 1) / epochs * 50))
                for batch_X, batch_y in train_loader:
                    optimizer.zero_grad()
                    output = model(batch_X)
                    loss = criterion(output, batch_y)
                    loss.backward()
                    optimizer.step()
                time.sleep(0.5)  # ƒê·ªô tr·ªÖ m·ªói epoch
            
            model.eval()
            with torch.no_grad():
                outputs = model(X_test)
                test_acc = (outputs.argmax(dim=1) == y_test).float().mean().item()
            
            st.write(f"üìä ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test: {test_acc:.4f}")
            mlflow.log_metric("pseudo_test_accuracy", test_acc, step=iteration)
            
            if len(X_unlabeled_remaining) == 0:
                break
            
            status_text.text("üîç ƒêang d·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu ch∆∞a g√°n...")
            with torch.no_grad():
                outputs = model(X_unlabeled_remaining)
                probs, predicted_labels = outputs.softmax(dim=1).max(dim=1)
            
            confident_mask = probs >= threshold
            X_confident = X_unlabeled_remaining[confident_mask]
            y_confident = predicted_labels[confident_mask]
            
            st.write(f"S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n gi·∫£: {X_confident.shape[0]} (ng∆∞·ª°ng: {threshold})")
            st.write(f"S·ªë m·∫´u ch∆∞a g√°n nh√£n c√≤n l·∫°i: {X_unlabeled_remaining.shape[0] - X_confident.shape[0]}")
            
            if len(X_confident) == 0:
                break
            
            X_labeled = torch.cat([X_labeled, X_confident])
            y_labeled = torch.cat([y_labeled, y_confident])
            X_unlabeled_remaining = X_unlabeled_remaining[~confident_mask]
            
            labeled_fraction = X_labeled.shape[0] / total_samples
            progress_bar.progress(min(int(50 + 50 * labeled_fraction), 100))
            status_text.text(f"üìà ƒê√£ g√°n nh√£n: {X_labeled.shape[0]}/{total_samples} m·∫´u ({labeled_fraction:.2%})")
            
            iteration += 1
            if loop_mode == "G√°n h·∫øt to√†n b·ªô t·∫≠p train" and len(X_unlabeled_remaining) == 0:
                break
        
        torch.save(model.state_dict(), "pseudo_model_final.pth")
        mlflow.log_artifact("pseudo_model_final.pth")
        mlflow.end_run()
        
        st.success("‚úÖ Qu√° tr√¨nh Pseudo Labelling ho√†n t·∫•t!")
        st.markdown(f"[üîó Xem MLflow tr√™n DAGsHub]({st.session_state['mlflow_url']})")


def Semi_supervised():
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    ) 
    st.markdown(" ### üñäÔ∏è MNIST NN & Semi-supervised App")
    tab1, tab2, tab3, tab4, tab5 = st.tabs(
    ["T·ªïng quan", 
    "T·∫£i d·ªØ li·ªáu",
    "Chia d·ªØ li·ªáu",
    "Hu·∫•n luy·ªán", 
    "Th√¥ng tin hu·∫•n luy·ªán"])

    with tab1: 
        tong_quan()
    with tab2: 
        up_load_db()
    with tab3: 
        chia_du_lieu()
    with tab4: 
        train2()
    with tab5:
        display_mlflow_experiments()
        
def run():
    Semi_supervised() 

if __name__ == "__main__":
    run()
